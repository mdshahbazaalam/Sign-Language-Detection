{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fe2d3f1",
   "metadata": {},
   "source": [
    "# Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f68c43d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import mediapipe as mp\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d580406",
   "metadata": {},
   "source": [
    "# Capture keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c93b4c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44fffdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_detection(image,model):\n",
    "    image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "    image.flags.writeable = False\n",
    "    results = model.process(image)\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image,cv2.COLOR_RGB2BGR)\n",
    "    return results, image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6159d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_landmarks(image,results):\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_CONTOURS,\n",
    "                             mp_drawing.DrawingSpec(color=(200,0,50), thickness=1, circle_radius=1),\n",
    "                             mp_drawing.DrawingSpec(color=(160,0,0), thickness=1, circle_radius=1))\n",
    "    \n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(0,0,255), thickness=2, circle_radius=2),\n",
    "                             mp_drawing.DrawingSpec(color=(0,255,0), thickness=2, circle_radius=2))\n",
    "    \n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(0,0,255), thickness=2, circle_radius=2),\n",
    "                             mp_drawing.DrawingSpec(color=(0,255,0), thickness=2, circle_radius=2))\n",
    "    \n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(0,0,255), thickness=2, circle_radius=2),\n",
    "                             mp_drawing.DrawingSpec(color=(0,255,0), thickness=2, circle_radius=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "554dafe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render():     # Not really needed, only for understanding perpose\n",
    "    camera = cv2.VideoCapture(0)\n",
    "    with mp_holistic.Holistic(min_detection_confidence = 0.7, min_tracking_confidence = 0.7) as holistic:\n",
    "        while camera.isOpened():\n",
    "            success, frame = camera.read()\n",
    "    \n",
    "            results, image = mediapipe_detection(frame,holistic)\n",
    "        \n",
    "            draw_landmarks(image, results)\n",
    "    \n",
    "            cv2.imshow('Video',image)\n",
    "    \n",
    "            if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                break\n",
    "        camera.release()\n",
    "        cv2.destroyAllWindows()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "01c85cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#results = render()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee3137f",
   "metadata": {},
   "source": [
    "# Extract Keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "771472f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keypoints(results):\n",
    "    pose = np.array([[res.x,res.y,res.z,res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*4)\n",
    "    face = np.array([[res.x,res.y,res.z] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(468*3)\n",
    "    lh = np.array([[res.x,res.y,res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "    rh = np.array([[res.x,res.y,res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "    return np.concatenate([pose,face,lh,rh])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5dbe39f",
   "metadata": {},
   "source": [
    "# Folder Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb924159",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"actions = np.array(['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S',\n",
    "                    'T','U','V','W','X','Y','Z','HELLO','HEY','_I','MY','NAME','YOU','YOUR','HOW ARE YOU',\n",
    "                    'I\\'M FINE','NICE','TO MEET YOU','WHERE','FROM','LIKE','WORK','MOVIE','WHAT',\n",
    "                    'WHAT TIME IS IT','WASHROOM','MEANING','SORRY','BAD','LOVE','WITH','WANT TO',\n",
    "                    'FAVOURITE','SIGN','PLEASE','THANK YOU','SEE YOU LATER','GOOD','MORNING','AFTERNOON',\n",
    "                    'NIGHT','TODAY','GO','COME','EXCUSE ME','GOOD BYE','TAKE CARE','FOR WATCHING','HAVE',\n",
    "                    'DAY','YES','NO','KNOW','LITTLE','EVERYONE','0','1','2','3','4','5','6','7','8','9']) \"\"\"\n",
    "\n",
    "actions = np.array(['HELLO','HEY','THANK YOU','GOOD','MORNING'])\n",
    "\n",
    "DATA_PATH = os.path.join('DATA')\n",
    "no_of_videos = 30\n",
    "no_of_frames = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32680826",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_folder(actions):\n",
    "    for action in actions:\n",
    "        for video_no in range(no_of_videos):\n",
    "            try:\n",
    "                os.makedirs(os.path.join(DATA_PATH,action,str(video_no)))\n",
    "            except:\n",
    "                print(\"Cannot create directorie!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a13aef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_folder(actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2f9727",
   "metadata": {},
   "source": [
    "# Data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b932ba4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_collect(actions):\n",
    "    no_of_videos = 30\n",
    "    no_of_frames = 30\n",
    "    camera = cv2.VideoCapture(0)\n",
    "    with mp_holistic.Holistic(min_detection_confidence = 0.5, min_tracking_confidence = 0.5) as holistic:\n",
    "        for action in actions:\n",
    "            for video_no in range(no_of_videos):\n",
    "                for frame_no in range(no_of_frames):\n",
    "                    success, frame = camera.read()\n",
    "\n",
    "                    results, image = mediapipe_detection(frame,holistic)\n",
    "\n",
    "                    draw_landmarks(image, results)\n",
    "                    \n",
    "                    if frame_no == 0:\n",
    "                        cv2.putText(image, 'Sart Recording...',(150,250),cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                                   1,(0,255,0),1,cv2.LINE_AA)\n",
    "                        cv2.putText(image,'Collecting data for: {}  video no: {}'.format(action,video_no),\n",
    "                                    (15,20),cv2.FONT_HERSHEY_SIMPLEX, 1, (255,0,0),1,cv2.LINE_AA)\n",
    "                        \n",
    "                        cv2.imshow('Data Collection...',image)\n",
    "                        \n",
    "                        cv2.waitKey(10)\n",
    "                    else:\n",
    "                        cv2.putText(image,'Collecting data for: {}  video no: {}'.format(action,video_no),\n",
    "                                    (15,20),cv2.FONT_HERSHEY_SIMPLEX, 1, (255,0,0),1,cv2.LINE_AA)\n",
    "                        cv2.imshow('Data Collection...',image)\n",
    "                    \n",
    "                    keypoint_array = extract_keypoints(results)\n",
    "                    \n",
    "                    array_path = os.path.join(DATA_PATH,action,str(video_no),str(frame_no))\n",
    "                    \n",
    "                    np.save(array_path,keypoint_array)\n",
    "\n",
    "                    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                        break\n",
    "        camera.release()\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "01a5e494",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collect(actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9725f1",
   "metadata": {},
   "source": [
    "#  Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68ef3dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {label:num for num, label in enumerate(actions)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40806871",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'HELLO': 0, 'HEY': 1, 'THANK YOU': 2, 'GOOD': 3, 'MORNING': 4}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7622eb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(actions):\n",
    "    videos, labels = [], []\n",
    "    for action in actions:\n",
    "        for video_no in range(no_of_videos):\n",
    "            video_array = []\n",
    "            for frame_no in range(no_of_frames):\n",
    "                res = np.load(os.path.join(DATA_PATH,action,str(video_no), \"{}.npy\".format(frame_no)))\n",
    "                video_array.append(res)\n",
    "            videos.append(video_array)\n",
    "            labels.append(label_map[action])\n",
    "    return np.array(videos), to_categorical(np.array(labels)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b1a827c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = preprocess_data(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0574d90e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 30, 1662)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c56cffe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_partition(x,y):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x , y, test_size = 0.05)\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "20360a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    " x_train, x_test, y_train, y_test = data_partition(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77dc9fcc",
   "metadata": {},
   "source": [
    "# TensorBoard Callback setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "585c55c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tb_setup():\n",
    "    log_dir = os.path.join('Logs')\n",
    "    tb_callback = TensorBoard(log_dir=log_dir)\n",
    "    return tb_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a4015932",
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_callback = tb_setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e9eb53ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.TensorBoard at 0x2b8968e1b80>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tb_callback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8191f3db",
   "metadata": {},
   "source": [
    "# Create Neural Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2b805c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_neuralnet(actions):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(64,return_sequences = True, activation = 'relu', input_shape = (30,1662)))\n",
    "    model.add(LSTM(128, return_sequences = True, activation = 'relu'))\n",
    "    model.add(LSTM(64, return_sequences = False, activation = 'relu'))\n",
    "    model.add(Dense(64, activation = 'relu'))\n",
    "    model.add(Dense(32, activation = 'relu'))\n",
    "    model.add(Dense(actions.shape[0],activation = 'softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8129abf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = setup_neuralnet(actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098deb86",
   "metadata": {},
   "source": [
    "# Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76abc8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'Adam', loss = 'categorical_crossentropy', metrics = ['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2f5ccc",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6b8e2e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "5/5 [==============================] - 16s 279ms/step - loss: 4.9357 - categorical_accuracy: 0.2535\n",
      "Epoch 2/1000\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 18.1504 - categorical_accuracy: 0.2183\n",
      "Epoch 3/1000\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 8.8984 - categorical_accuracy: 0.1479\n",
      "Epoch 4/1000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 64.4696 - categorical_accuracy: 0.1197\n",
      "Epoch 5/1000\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 104.7631 - categorical_accuracy: 0.1690\n",
      "Epoch 6/1000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 49.0197 - categorical_accuracy: 0.2394\n",
      "Epoch 7/1000\n",
      "5/5 [==============================] - 1s 195ms/step - loss: 46.9835 - categorical_accuracy: 0.1972\n",
      "Epoch 8/1000\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 21.7379 - categorical_accuracy: 0.1761\n",
      "Epoch 9/1000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 27.8233 - categorical_accuracy: 0.1761\n",
      "Epoch 10/1000\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 16.5527 - categorical_accuracy: 0.1901\n",
      "Epoch 11/1000\n",
      "5/5 [==============================] - 1s 207ms/step - loss: 22.2336 - categorical_accuracy: 0.2887\n",
      "Epoch 12/1000\n",
      "5/5 [==============================] - 1s 155ms/step - loss: 14.0724 - categorical_accuracy: 0.1972\n",
      "Epoch 13/1000\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 7.5162 - categorical_accuracy: 0.2394\n",
      "Epoch 14/1000\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 4.2444 - categorical_accuracy: 0.2465\n",
      "Epoch 15/1000\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 2.2874 - categorical_accuracy: 0.3944\n",
      "Epoch 16/1000\n",
      "5/5 [==============================] - 1s 142ms/step - loss: 1.5290 - categorical_accuracy: 0.4437\n",
      "Epoch 17/1000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 1.1215 - categorical_accuracy: 0.5141\n",
      "Epoch 18/1000\n",
      "5/5 [==============================] - 1s 207ms/step - loss: 1.0644 - categorical_accuracy: 0.5493\n",
      "Epoch 19/1000\n",
      "5/5 [==============================] - 1s 156ms/step - loss: 0.9343 - categorical_accuracy: 0.5915\n",
      "Epoch 20/1000\n",
      "5/5 [==============================] - 1s 163ms/step - loss: 0.9697 - categorical_accuracy: 0.5775\n",
      "Epoch 21/1000\n",
      "5/5 [==============================] - 1s 159ms/step - loss: 0.9501 - categorical_accuracy: 0.5563\n",
      "Epoch 22/1000\n",
      "5/5 [==============================] - 1s 163ms/step - loss: 0.9762 - categorical_accuracy: 0.5986\n",
      "Epoch 23/1000\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.8509 - categorical_accuracy: 0.6620\n",
      "Epoch 24/1000\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 0.9370 - categorical_accuracy: 0.6056\n",
      "Epoch 25/1000\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.7864 - categorical_accuracy: 0.6197\n",
      "Epoch 26/1000\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 0.7195 - categorical_accuracy: 0.6549\n",
      "Epoch 27/1000\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 0.7452 - categorical_accuracy: 0.6268\n",
      "Epoch 28/1000\n",
      "5/5 [==============================] - 1s 305ms/step - loss: 0.8731 - categorical_accuracy: 0.6056\n",
      "Epoch 29/1000\n",
      "5/5 [==============================] - 1s 252ms/step - loss: 0.7835 - categorical_accuracy: 0.6479\n",
      "Epoch 30/1000\n",
      "5/5 [==============================] - 1s 266ms/step - loss: 0.7394 - categorical_accuracy: 0.6901\n",
      "Epoch 31/1000\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.7035 - categorical_accuracy: 0.7042\n",
      "Epoch 32/1000\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.7128 - categorical_accuracy: 0.6690\n",
      "Epoch 33/1000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.6602 - categorical_accuracy: 0.7465\n",
      "Epoch 34/1000\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.6755 - categorical_accuracy: 0.7042\n",
      "Epoch 35/1000\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 0.8155 - categorical_accuracy: 0.6620\n",
      "Epoch 36/1000\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 0.9679 - categorical_accuracy: 0.5986\n",
      "Epoch 37/1000\n",
      "5/5 [==============================] - 1s 141ms/step - loss: 0.8660 - categorical_accuracy: 0.6268\n",
      "Epoch 38/1000\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 1.2369 - categorical_accuracy: 0.5775\n",
      "Epoch 39/1000\n",
      "5/5 [==============================] - 1s 110ms/step - loss: 1.1383 - categorical_accuracy: 0.5845\n",
      "Epoch 40/1000\n",
      "5/5 [==============================] - 1s 105ms/step - loss: 1.1340 - categorical_accuracy: 0.5775\n",
      "Epoch 41/1000\n",
      "5/5 [==============================] - 1s 110ms/step - loss: 1.1328 - categorical_accuracy: 0.5493\n",
      "Epoch 42/1000\n",
      "5/5 [==============================] - 1s 115ms/step - loss: 0.8151 - categorical_accuracy: 0.6408\n",
      "Epoch 43/1000\n",
      "5/5 [==============================] - 1s 114ms/step - loss: 0.6793 - categorical_accuracy: 0.7042\n",
      "Epoch 44/1000\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 0.6388 - categorical_accuracy: 0.7113\n",
      "Epoch 45/1000\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.7122 - categorical_accuracy: 0.6761\n",
      "Epoch 46/1000\n",
      "5/5 [==============================] - 1s 113ms/step - loss: 0.6556 - categorical_accuracy: 0.7606\n",
      "Epoch 47/1000\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.7290 - categorical_accuracy: 0.6901\n",
      "Epoch 48/1000\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 0.7237 - categorical_accuracy: 0.6690\n",
      "Epoch 49/1000\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 0.7197 - categorical_accuracy: 0.6690\n",
      "Epoch 50/1000\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.7439 - categorical_accuracy: 0.6901\n",
      "Epoch 51/1000\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.6373 - categorical_accuracy: 0.7535\n",
      "Epoch 52/1000\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 0.5057 - categorical_accuracy: 0.7887\n",
      "Epoch 53/1000\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.5879 - categorical_accuracy: 0.7676\n",
      "Epoch 54/1000\n",
      "5/5 [==============================] - 1s 161ms/step - loss: 0.6383 - categorical_accuracy: 0.7254\n",
      "Epoch 55/1000\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.8164 - categorical_accuracy: 0.6901\n",
      "Epoch 56/1000\n",
      "5/5 [==============================] - 1s 156ms/step - loss: 1.0658 - categorical_accuracy: 0.6408\n",
      "Epoch 57/1000\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.8404 - categorical_accuracy: 0.6690\n",
      "Epoch 58/1000\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.7183 - categorical_accuracy: 0.6901\n",
      "Epoch 59/1000\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 0.6702 - categorical_accuracy: 0.6831\n",
      "Epoch 60/1000\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.6227 - categorical_accuracy: 0.6901\n",
      "Epoch 61/1000\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 0.9604 - categorical_accuracy: 0.6549\n",
      "Epoch 62/1000\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 4.7974 - categorical_accuracy: 0.2465\n",
      "Epoch 63/1000\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 7.3294 - categorical_accuracy: 0.1901\n",
      "Epoch 64/1000\n",
      "5/5 [==============================] - 1s 110ms/step - loss: 4.4496 - categorical_accuracy: 0.2254\n",
      "Epoch 65/1000\n",
      "5/5 [==============================] - 1s 109ms/step - loss: 5.5004 - categorical_accuracy: 0.1972\n",
      "Epoch 66/1000\n",
      "5/5 [==============================] - 1s 114ms/step - loss: 2.1921 - categorical_accuracy: 0.1831\n",
      "Epoch 67/1000\n",
      "5/5 [==============================] - 1s 114ms/step - loss: 1.6143 - categorical_accuracy: 0.2465\n",
      "Epoch 68/1000\n",
      "5/5 [==============================] - 1s 114ms/step - loss: 1.4804 - categorical_accuracy: 0.3310\n",
      "Epoch 69/1000\n",
      "5/5 [==============================] - 1s 115ms/step - loss: 1.4415 - categorical_accuracy: 0.3169\n",
      "Epoch 70/1000\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 1.2277 - categorical_accuracy: 0.4225\n",
      "Epoch 71/1000\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 1.2160 - categorical_accuracy: 0.3873\n",
      "Epoch 72/1000\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 1.3208 - categorical_accuracy: 0.3944\n",
      "Epoch 73/1000\n",
      "5/5 [==============================] - 1s 118ms/step - loss: 1.1752 - categorical_accuracy: 0.3873\n",
      "Epoch 74/1000\n",
      "5/5 [==============================] - 1s 141ms/step - loss: 1.0196 - categorical_accuracy: 0.4366\n",
      "Epoch 75/1000\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 0.9429 - categorical_accuracy: 0.5634\n",
      "Epoch 76/1000\n",
      "5/5 [==============================] - 1s 141ms/step - loss: 0.9421 - categorical_accuracy: 0.4930\n",
      "Epoch 77/1000\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.8944 - categorical_accuracy: 0.5986\n",
      "Epoch 78/1000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.8939 - categorical_accuracy: 0.5352\n",
      "Epoch 79/1000\n",
      "5/5 [==============================] - 1s 142ms/step - loss: 0.8516 - categorical_accuracy: 0.6338\n",
      "Epoch 80/1000\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.8215 - categorical_accuracy: 0.6268\n",
      "Epoch 81/1000\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.8143 - categorical_accuracy: 0.6620\n",
      "Epoch 82/1000\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.7923 - categorical_accuracy: 0.5986\n",
      "Epoch 83/1000\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.8107 - categorical_accuracy: 0.7465\n",
      "Epoch 84/1000\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.7946 - categorical_accuracy: 0.7465\n",
      "Epoch 85/1000\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 0.7449 - categorical_accuracy: 0.6761\n",
      "Epoch 86/1000\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.7284 - categorical_accuracy: 0.7676\n",
      "Epoch 87/1000\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.7233 - categorical_accuracy: 0.7676\n",
      "Epoch 88/1000\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.8068 - categorical_accuracy: 0.6056\n",
      "Epoch 89/1000\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 0.6906 - categorical_accuracy: 0.7465\n",
      "Epoch 90/1000\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 0.6817 - categorical_accuracy: 0.7676\n",
      "Epoch 91/1000\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.7384 - categorical_accuracy: 0.7113\n",
      "Epoch 92/1000\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.7245 - categorical_accuracy: 0.6268\n",
      "Epoch 93/1000\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.7686 - categorical_accuracy: 0.5704\n",
      "Epoch 94/1000\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 0.6523 - categorical_accuracy: 0.7535\n",
      "Epoch 95/1000\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 0.6607 - categorical_accuracy: 0.7183\n",
      "Epoch 96/1000\n",
      "5/5 [==============================] - 1s 190ms/step - loss: 0.6112 - categorical_accuracy: 0.7324\n",
      "Epoch 97/1000\n",
      "5/5 [==============================] - 1s 173ms/step - loss: 0.5763 - categorical_accuracy: 0.8028\n",
      "Epoch 98/1000\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.5736 - categorical_accuracy: 0.8239\n",
      "Epoch 99/1000\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 0.6279 - categorical_accuracy: 0.7535\n",
      "Epoch 100/1000\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.5630 - categorical_accuracy: 0.8099\n",
      "Epoch 101/1000\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.5450 - categorical_accuracy: 0.8028\n",
      "Epoch 102/1000\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 0.4679 - categorical_accuracy: 0.8732\n",
      "Epoch 103/1000\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 0.4474 - categorical_accuracy: 0.8521\n",
      "Epoch 104/1000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.4287 - categorical_accuracy: 0.8732\n",
      "Epoch 105/1000\n",
      "5/5 [==============================] - 1s 163ms/step - loss: 0.5236 - categorical_accuracy: 0.7606\n",
      "Epoch 106/1000\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 0.5347 - categorical_accuracy: 0.7887\n",
      "Epoch 107/1000\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.4519 - categorical_accuracy: 0.8380\n",
      "Epoch 108/1000\n",
      "5/5 [==============================] - 1s 141ms/step - loss: 0.4233 - categorical_accuracy: 0.8732\n",
      "Epoch 109/1000\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.4271 - categorical_accuracy: 0.8662\n",
      "Epoch 110/1000\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 0.4343 - categorical_accuracy: 0.8521\n",
      "Epoch 111/1000\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.3937 - categorical_accuracy: 0.8662\n",
      "Epoch 112/1000\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 0.3611 - categorical_accuracy: 0.8944\n",
      "Epoch 113/1000\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 0.4050 - categorical_accuracy: 0.8803\n",
      "Epoch 114/1000\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 0.3652 - categorical_accuracy: 0.8803\n",
      "Epoch 115/1000\n",
      "5/5 [==============================] - 1s 155ms/step - loss: 0.3796 - categorical_accuracy: 0.8732\n",
      "Epoch 116/1000\n",
      "5/5 [==============================] - 1s 161ms/step - loss: 0.4193 - categorical_accuracy: 0.8380\n",
      "Epoch 117/1000\n",
      "5/5 [==============================] - 1s 174ms/step - loss: 0.3536 - categorical_accuracy: 0.8803\n",
      "Epoch 118/1000\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.3786 - categorical_accuracy: 0.8451\n",
      "Epoch 119/1000\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.3836 - categorical_accuracy: 0.8380\n",
      "Epoch 120/1000\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.3460 - categorical_accuracy: 0.8592\n",
      "Epoch 121/1000\n",
      "5/5 [==============================] - 1s 114ms/step - loss: 0.3467 - categorical_accuracy: 0.8732\n",
      "Epoch 122/1000\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.3488 - categorical_accuracy: 0.8873\n",
      "Epoch 123/1000\n",
      "5/5 [==============================] - 1s 114ms/step - loss: 0.4007 - categorical_accuracy: 0.8451\n",
      "Epoch 124/1000\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.3451 - categorical_accuracy: 0.8873\n",
      "Epoch 125/1000\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.3949 - categorical_accuracy: 0.8521\n",
      "Epoch 126/1000\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.3249 - categorical_accuracy: 0.8662\n",
      "Epoch 127/1000\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 0.3344 - categorical_accuracy: 0.8732\n",
      "Epoch 128/1000\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.2651 - categorical_accuracy: 0.9155\n",
      "Epoch 129/1000\n",
      "5/5 [==============================] - 1s 140ms/step - loss: 0.2964 - categorical_accuracy: 0.9014\n",
      "Epoch 130/1000\n",
      "5/5 [==============================] - 1s 140ms/step - loss: 0.3368 - categorical_accuracy: 0.8592\n",
      "Epoch 131/1000\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.3559 - categorical_accuracy: 0.8732\n",
      "Epoch 132/1000\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.3101 - categorical_accuracy: 0.8732\n",
      "Epoch 133/1000\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.3216 - categorical_accuracy: 0.8803\n",
      "Epoch 134/1000\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.2725 - categorical_accuracy: 0.9014\n",
      "Epoch 135/1000\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 0.3313 - categorical_accuracy: 0.8662\n",
      "Epoch 136/1000\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.3077 - categorical_accuracy: 0.8873\n",
      "Epoch 137/1000\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 0.2567 - categorical_accuracy: 0.9014\n",
      "Epoch 138/1000\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.2909 - categorical_accuracy: 0.9014\n",
      "Epoch 139/1000\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 0.2586 - categorical_accuracy: 0.9155\n",
      "Epoch 140/1000\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.2393 - categorical_accuracy: 0.9155\n",
      "Epoch 141/1000\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.2384 - categorical_accuracy: 0.9014\n",
      "Epoch 142/1000\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.2714 - categorical_accuracy: 0.8944\n",
      "Epoch 143/1000\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 0.2259 - categorical_accuracy: 0.9225\n",
      "Epoch 144/1000\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.3274 - categorical_accuracy: 0.8803\n",
      "Epoch 145/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 124ms/step - loss: 0.3344 - categorical_accuracy: 0.8521\n",
      "Epoch 146/1000\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 0.2688 - categorical_accuracy: 0.9085\n",
      "Epoch 147/1000\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 0.2312 - categorical_accuracy: 0.9225\n",
      "Epoch 148/1000\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 0.2528 - categorical_accuracy: 0.9155\n",
      "Epoch 149/1000\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.2297 - categorical_accuracy: 0.8944\n",
      "Epoch 150/1000\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.2380 - categorical_accuracy: 0.9155\n",
      "Epoch 151/1000\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 0.2567 - categorical_accuracy: 0.8873\n",
      "Epoch 152/1000\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 0.3724 - categorical_accuracy: 0.8239\n",
      "Epoch 153/1000\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 0.2744 - categorical_accuracy: 0.9085\n",
      "Epoch 154/1000\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.3222 - categorical_accuracy: 0.8521\n",
      "Epoch 155/1000\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 0.4106 - categorical_accuracy: 0.8451\n",
      "Epoch 156/1000\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.3266 - categorical_accuracy: 0.8944\n",
      "Epoch 157/1000\n",
      "5/5 [==============================] - 1s 141ms/step - loss: 0.3260 - categorical_accuracy: 0.8873\n",
      "Epoch 158/1000\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.3394 - categorical_accuracy: 0.8310\n",
      "Epoch 159/1000\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.2939 - categorical_accuracy: 0.9155\n",
      "Epoch 160/1000\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 0.2412 - categorical_accuracy: 0.9085\n",
      "Epoch 161/1000\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.2895 - categorical_accuracy: 0.8944\n",
      "Epoch 162/1000\n",
      "5/5 [==============================] - 1s 142ms/step - loss: 0.3145 - categorical_accuracy: 0.9085\n",
      "Epoch 163/1000\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 0.2534 - categorical_accuracy: 0.9296\n",
      "Epoch 164/1000\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.2476 - categorical_accuracy: 0.9085\n",
      "Epoch 165/1000\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 0.2846 - categorical_accuracy: 0.9014\n",
      "Epoch 166/1000\n",
      "5/5 [==============================] - 1s 162ms/step - loss: 0.2219 - categorical_accuracy: 0.9366\n",
      "Epoch 167/1000\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.6267 - categorical_accuracy: 0.9155\n",
      "Epoch 168/1000\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.3554 - categorical_accuracy: 0.8662\n",
      "Epoch 169/1000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.4196 - categorical_accuracy: 0.7887\n",
      "Epoch 170/1000\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.3835 - categorical_accuracy: 0.8873\n",
      "Epoch 171/1000\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 0.2971 - categorical_accuracy: 0.9014\n",
      "Epoch 172/1000\n",
      "4/5 [=======================>......] - ETA: 0s - loss: 0.2532 - categorical_accuracy: 0.9141"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9840/1779846400.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtb_callback\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[1;31m# No error, now safe to assign to logs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1220\u001b[1;33m               \u001b[0mend_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1221\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1222\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36mstep_increment\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1268\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_steps_per_execution\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moriginal_spe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1269\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1270\u001b[1;33m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1271\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mstep_increment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1272\u001b[0m     \u001b[1;34m\"\"\"The number to increment the step for `on_batch_end` methods.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs = 1000,callbacks = [tb_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd0ae26",
   "metadata": {},
   "source": [
    "# Testing for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32e1ebfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 30, 64)            442112    \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 30, 128)           98816     \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 64)                49408     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 5)                 165       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 596,741\n",
      "Trainable params: 596,741\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "86601e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f0c85731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'THANK YOU'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions[np.argmax(res[3])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ba320eb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'THANK YOU'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions[np.argmax(y_test[3])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e686b8d",
   "metadata": {},
   "source": [
    "# Saving the trained model weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "abcf0f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7923fb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to reload model-weight\n",
    "model.load_weights('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4234f81b",
   "metadata": {},
   "source": [
    "# Evaluating the performance using Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c56f256e",
   "metadata": {},
   "outputs": [],
   "source": [
    " from sklearn.metrics import multilabel_confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d4fea94",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6576/1265334177.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0myhat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'x_test' is not defined"
     ]
    }
   ],
   "source": [
    "yhat = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "044bf58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrue = np.argmax(y_test,axis=1).tolist()\n",
    "yhat = np.argmax(yhat,axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "cd76161d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[6, 0],\n",
       "        [0, 2]],\n",
       "\n",
       "       [[3, 1],\n",
       "        [0, 4]],\n",
       "\n",
       "       [[7, 0],\n",
       "        [1, 0]],\n",
       "\n",
       "       [[7, 0],\n",
       "        [0, 1]]], dtype=int64)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multilabel_confusion_matrix(ytrue,yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "220ffb11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.875"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ytrue,yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d751a8",
   "metadata": {},
   "source": [
    "# Real-time prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de7774e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def real_time_detection(model,actions):\n",
    "    video = []\n",
    "    sentence = []\n",
    "    threshold = 0.4\n",
    "    camera = cv2.VideoCapture(0)\n",
    "    with mp_holistic.Holistic(min_detection_confidence = 0.7, min_tracking_confidence = 0.7) as holistic:\n",
    "        while camera.isOpened():\n",
    "            success, frame = camera.read()\n",
    "    \n",
    "            results, image = mediapipe_detection(frame,holistic)\n",
    "        \n",
    "            draw_landmarks(image, results)\n",
    "            \n",
    "            keypoints = extract_keypoints(results)\n",
    "            video.append(keypoints)\n",
    "            video = video[-30:]\n",
    "            if results.left_hand_landmarks or results.right_hand_landmarks:\n",
    "                if len(video) == 30:\n",
    "                    res = model.predict(np.expand_dims(video,axis=0))[0]\n",
    "            \n",
    "                    if res[np.argmax(res)] > threshold:\n",
    "                        if len(sentence) > 0:\n",
    "                            if sentence[-1] != actions[np.argmax(res)]:\n",
    "                                sentence.append(actions[np.argmax(res)])  \n",
    "                        else:\n",
    "                            sentence.append(actions[np.argmax(res)])\n",
    "                    \n",
    "                        if len(sentence) > 5:\n",
    "                            sentence = sentence[-5:]\n",
    "                \n",
    "                \n",
    "            cv2.rectangle(image,(0,0),(640,40),(245,116,17),-1)\n",
    "                \n",
    "            cv2.putText(image, ' '.join(sentence),(3,30), cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),\n",
    "                           2,cv2.LINE_AA)\n",
    "    \n",
    "            cv2.imshow('Sign Language Detection',image)\n",
    "    \n",
    "            if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                break\n",
    "        camera.release()\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9b8f34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_time_detection(model,actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0ac8c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
